{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling, Accuracy Example\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, speed comparisons between the BAPE algorithm and the \"brute force\" method of just using your forward model for Bayesian parameter inference using MCMC (see https://github.com/dfm/emcee for our MCMC algorithm).  We run the BAPE algorithm on the Wang & Li (2017) Rosenbrock function example and consider cases where instead of the ${\\sim}10\\mu$s runtime of the analytic Rosenbrock function, it took anywhere from $10^{-3}$s to $10^{4}$s.  This exercise allows to us crudely estimate how slow a forward model must be before using approximate methods such as ```approxposterior``` is warranted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import (print_function, division, absolute_import,\n",
    "                        unicode_literals)\n",
    "from approxposterior import bp, likelihood as lh\n",
    "import corner\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize and run the BAPE Algorithm example as was done in the BAPE_Example notebook.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m0 = 20                           # Initial size of training set\n",
    "m = 10                            # Number of new points to find each iteration\n",
    "nmax = 20                         # Maximum number of iterations\n",
    "M = int(2.0e4)                    # Number of MCMC steps to estimate approximate posterior\n",
    "Dmax = 0.01                        # KL-Divergence convergence limit\n",
    "kmax = 5                          # Number of iterations for Dmax convergence to kick in\n",
    "which_kernel = \"ExpSquaredKernel\" # Which Gaussian Process kernel to use\n",
    "bounds = ((-5,5), (-5,5))         # Prior bounds\n",
    "algorithm = \"bape\"                 # Use the Kandasamy et al. (2015) formalism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ap = bp.ApproxPosterior(lnprior=lh.rosenbrock_lnprior,\n",
    "                        lnlike=lh.rosenbrock_lnlike,\n",
    "                        prior_sample=lh.rosenbrock_sample,\n",
    "                        algorithm=algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This time, turn on the timing option with timing=True in the run method.**\n",
    "\n",
    "---\n",
    "\n",
    "Setting ```timing=True``` allows the code to profile how long various parts of the algorithm take to run.  If ```timing=True```, then the code keeps track of, for each iteration, how long it takes to find/retrain the Gaussian Process for the $m$ new design points, run the MCMC, fit the Gaussian Mixture Model approximation to the joint posterior distribution, and estimate the KL divergence between the current and previous joint posterior distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dflemin3/Dropbox/approxposterior/approxposterior/utility.py:93: RuntimeWarning: invalid value encountered in log\n",
      "  res = np.sum(np.log(p(x)/q(x)))/len(x)\n"
     ]
    }
   ],
   "source": [
    "# Run!\n",
    "ap.run(m0=m0, m=m, M=M, nmax=nmax, Dmax=Dmax, kmax=kmax,\n",
    "       bounds=bounds, which_kernel=which_kernel,\n",
    "       n_kl_samples=100000, verbose=False, debug=False,\n",
    "       timing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estimate Time Scaling as a Function of Forward Model Time**\n",
    "\n",
    "---\n",
    "\n",
    "Now, we're going to pretend that our forward model takes anywhere $10^{-5}$s to $10^{4}$s for one evaluation.  In the \"brute force\" method, for each iteration for each walker, the MCMC algorithm runs the forward model, typically resulting in $>10^5$ forward model evaluations!  Obviously for slow forward models, this readily becomes computationaly intractible (unless you're willing to wait PhD timescales for it to finish!).  Here, we show how the \"brute force\" method fairs compared to ```approxposterior```'s BAPE implementation.  In this section, we take care to accurately time all facets of the algorithm while factoring in different forward model evaluation times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create synthetic forward model times in seconds\n",
    "ns = np.logspace(-5,4,10)\n",
    "\n",
    "# Number of evluations in the MCMC chain\n",
    "niters = len(ap.samplers[-1].flatchain)\n",
    "\n",
    "# \"Brute force\" times are the number of evaluations times the forward model evaluation time\n",
    "brute_times = ns*niters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute GP training time factoring in synthetic forward model run times\n",
    "gp_times = np.zeros(len(ns))\n",
    "\n",
    "for ii in range(len(ns)):\n",
    "    # The algorithm initializes with m0 forward model evaluations\n",
    "    gp_times[ii] = m0*ns[ii]\n",
    "    \n",
    "    # Loop over iterations\n",
    "    for jj in range(len(ap.training_time)):\n",
    "        # Add time of running forward model to get m new points and training GP, running mcmc, \n",
    "        # change in KL divergence, and GMM estimation times\n",
    "        gp_times[ii] += m*ns[ii] + ap.training_time[jj] + ap.mcmc_time[jj] + ap.kl_time[jj] + ap.gmm_time[jj]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the scalings to see where both methods are faster!**\n",
    "\n",
    "---\n",
    "\n",
    "Below, we plot the total time it takes for the full Bayesian parameter inference (y axis) as a function of forward model evaluation time (x axis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9,8))\n",
    "\n",
    "ax.plot(ns, brute_times, \"o-\", lw=2.5, label=\"Brute Force\")\n",
    "ax.plot(ns, gp_times, \"o-\", lw=2.5, label=\"GP Approximation\")\n",
    "\n",
    "# Reference year, month, week, day, hour timescales\n",
    "ax.axhline((365*24*60*60), lw=2, ls=\"--\", color=\"k\", zorder=0)\n",
    "ax.axhline((30*24*60*60), lw=2, ls=\"--\", color=\"k\", zorder=0)\n",
    "ax.axhline((7*24*60*60), lw=2, ls=\"--\", color=\"k\", zorder=0)\n",
    "ax.axhline((24*60*60), lw=2, ls=\"--\", color=\"k\", zorder=0)\n",
    "ax.axhline((60*60), lw=2, ls=\"--\", color=\"k\", zorder=0)\n",
    "\n",
    "# One minute forward model reference\n",
    "ax.axvline(60, lw=2, ls=\":\", color=\"k\", zorder=3)\n",
    "\n",
    "ax.text(1.0e-5, 4.0e7, \"Year\")\n",
    "ax.text(1.0e-5, 3.5e6, \"Month\")\n",
    "ax.text(1.0e-5, 7.0e5, \"Week\")\n",
    "ax.text(1.0e-5, 1.2e5, \"Day\")\n",
    "ax.text(1.0e-5, 4.4e3, \"Hour\")\n",
    "\n",
    "ax.set_ylabel(\"Total Computational Time [s]\")\n",
    "ax.set_xlabel(\"Time per Forward Model Evaluation [s]\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "\n",
    "fig.savefig(\"scaling.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two clear regimes in this figure.  For very fast forward models, $t<10^{-2}$s per evaluation, it's slower to train the Gaussian process then actually run the MCMC using the true forward model, so in this case it's not worth using approximate methods.  For slow forward models, $t>10$s per model evaluation, most of the time is spent running the forward model to give training points to the Gaussian process, so the actual MCMC inference is relatively computationally cheap (GP predictions take of order milliseconds!).\n",
    "\n",
    "The turnover when it's faster to use ```approxposterior``` occurs once the forward model takes ${\\sim}10^{-2}$s to run.  At that point, however, it takes of order minutes to run the entire parameter inference, so there is no practical gain.  Once the forward model takes a few minutes to run, however, the approximate method completes in of order hours while the brute force method can take up to a month -- a massive speed-up! \n",
    "\n",
    "Strictly speaking, this scaling plot applies to the Rosenbrock function example from Wang & Li (2017).  Scaling plots like the one above depend on how many MCMC iterations you use, the MCMC algorithm, how many samples the GP is trained on, and probably the GP kernel.  For example, longer MCMCs have a raised floor for the flat region of the GP approximation curve and dictate when the turnover occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For slow forward models, the approximate methods are clearly faster.  But how accurate are the results?**\n",
    "\n",
    "---\n",
    "\n",
    "Above, we used the exact algorithm parameters Wang & Li (2017) used for their Rosenbrock function example.  In the True_Rosenbrock_Posterior example notebook, we ran an MCMC inference using the true Rosenbrock function likelihood and algorithm parameters from Wang & Li (2017) to derive the \"true\" joint posterior distribution.  Below, we visually and numerically compare the approximation to the joint posterior distribution derived above with true distribution to see how accurate the approximate method is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in the true chains from the True_Rosenbrock_Posterior example notebook\n",
    "true_mcmc = np.load(\"true_rosenbrock.npz\")\n",
    "true_flatchain = true_mcmc[\"flatchain\"]\n",
    "true_iburn = true_mcmc[\"iburn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,6))\n",
    "\n",
    "bins = 20\n",
    "\n",
    "# Plot GP approximation to the joint distribution\n",
    "corner.hist2d(ap.samplers[-1].flatchain[ap.iburns[-1]:,0], ap.samplers[-1].flatchain[ap.iburns[-1]:,1], \n",
    "              bins=bins, ax=ax, color=\"C3\", plot_density=False, plot_contours=True, plot_datapoints=False,\n",
    "             label=\"GP Approximation\")\n",
    "\n",
    "# Plot the true joint distribution\n",
    "corner.hist2d(true_flatchain[true_iburn:,0], true_flatchain[true_iburn:,1], bins=bins,\n",
    "              ax=ax, color=\"black\", plot_density=True, plot_contours=False, plot_datapoints=False)\n",
    "\n",
    "# Formating\n",
    "ax.text(-4, -3.25, \"Truth\", color=\"black\")\n",
    "ax.text(-4, -3.75, \"GP Approximation\", color=\"C3\")\n",
    "ax.set_xlabel(\"x0\")\n",
    "ax.set_ylabel(\"x1\")\n",
    "\n",
    "fig.savefig(\"accuracy.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The true and approximate distributions look nearly identical!  How do the 0.16, 0.5, 0.84 quantiles compare for the 2 parameters, x0 and x1? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "approx_x0 = np.percentile(ap.samplers[-1].flatchain[ap.iburns[-1]:,0],[0.16, 0.5, 0.84])\n",
    "approx_x1 = np.percentile(ap.samplers[-1].flatchain[ap.iburns[-1]:,1],[0.16, 0.5, 0.84])\n",
    "\n",
    "true_x0 = np.percentile(true_flatchain[true_iburn:,0],[0.16, 0.5, 0.84])\n",
    "true_x1 = np.percentile(true_flatchain[true_iburn:,1],[0.16, 0.5, 0.84])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x0\")\n",
    "print(\"True\\t\", true_x0)\n",
    "print(\"Approx\\t\", approx_x0)\n",
    "print(\"\")\n",
    "print(\"x1\")\n",
    "print(\"True\\t\", true_x1)\n",
    "print(\"Approx\\t\", approx_x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good, but let's visualize this instead..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9,8))\n",
    "\n",
    "# True, approx x0\n",
    "ax.errorbar([0], [true_x0[1]], yerr=[(true_x0[2], true_x0[0])], fmt='-o', color=\"C0\", label=\"True\")\n",
    "ax.errorbar([0.1], [approx_x0[1]], yerr=[(approx_x0[2], approx_x0[0])], fmt='-o', color=\"C1\", label=\"Approx\")\n",
    "\n",
    "# True, approx x1\n",
    "ax.errorbar([1], [true_x1[1]], yerr=[(true_x1[0], true_x1[2])], fmt='-o', color=\"C0\")\n",
    "ax.errorbar([1.1], [approx_x1[1]], yerr=[(approx_x1[0], approx_x1[2])], fmt='-o', color=\"C1\")\n",
    "\n",
    "# Format\n",
    "xticks = [0, 1]\n",
    "labels = [\"x0\", \"x1\"]\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(labels)\n",
    "\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"Parameter Value\")\n",
    "ax.set_xlim(-1,2)\n",
    "ax.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answers are consistent and nearly identical - great!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
