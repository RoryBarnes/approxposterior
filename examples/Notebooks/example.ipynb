{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAPE Algorithm Example\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, I work through an example using the \"Bayesian Active Learning for Posterior Estimation\" (BAPE) algorithm developed by Kandasamy et al. (2015).  The \"forward model\" I will use in this example is the Rosenbrock function likelihood examined in Wang & Li (2017).  \n",
    "\n",
    "Note: running this notebook with cache = True will create 10 large hdf5 files that hold the MCMC chains!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dflemin3/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from approxposterior import approx, likelihood as lh, gpUtils as gpu, utility as ut\n",
    "\n",
    "import george\n",
    "import corner\n",
    "import emcee\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams.update({'font.size': 18})\n",
    "\n",
    "# Tidy up the notebook (I'm not sweeping errors under the rug, I swear!)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, define model parameters.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define algorithm parameters\n",
    "m0 = 50                           # Initial size of training set\n",
    "m = 20                            # Number of new points to find each iteration\n",
    "nmax = 3                          # Maximum number of iterations\n",
    "bounds = ((-5,5), (-5,5))         # Prior bounds\n",
    "algorithm = \"BAPE\"                # Use the Kandasamy et al. (2015) formalism\n",
    "\n",
    "# emcee MCMC parameters\n",
    "samplerKwargs = {\"nwalkers\" : 20}        # emcee.EnsembleSampler parameters\n",
    "mcmcKwargs = {\"iterations\" : int(1.0e4)} # emcee.EnsembleSampler.run_mcmc parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a Gaussian Process Object using george**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate initial conditions using Latin Hypercube sampling over parameter bounds\n",
    "theta = ut.latinHypercubeSampling(m0, bounds, criterion=\"maximin\")\n",
    "\n",
    "# Evaluate forward model log likelihood + lnprior for each theta\n",
    "y = np.zeros(len(theta))\n",
    "for ii in range(len(theta)):\n",
    "    y[ii] = lh.rosenbrockLnlike(theta[ii]) + lh.rosenbrockLnprior(theta[ii])\n",
    "\n",
    "### Initialize GP ###\n",
    "gp = gpu.defaultGP(theta, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize object with required parameters**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize object using the Wang & Li (2017) Rosenbrock function example\n",
    "ap = approx.ApproxPosterior(theta=theta,\n",
    "                            y=y,\n",
    "                            gp=gp,\n",
    "                            lnprior=lh.rosenbrockLnprior,\n",
    "                            lnlike=lh.rosenbrockLnlike,\n",
    "                            priorSample=lh.rosenbrockSample,\n",
    "                            algorithm=algorithm,\n",
    "                            bounds=bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the forward model is wrapped up into the lnlike, or log-likelihood function.  This function evaluates the forward model and returns the log-likelihood of the forward model output.  This is the function we seek to call as *few* times as possible given how computationally expensive it is.  If you're not using a computationally expensive model (run times of less that a few minutes), you probably do not need to use this code!\n",
    "\n",
    "The other functions, lnprior and prior_sample, evaluate the prior probability of a data point and yield samples from the prior probability distributions, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With everything designated and initialized, run the algorithm!**\n",
    "\n",
    "---\n",
    "\n",
    "Note that with cache = True, approxposterior will create a apRunii.h5 file for each iteration ii.  These files, created by emcee, stores all the MCMC chain information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run!\n",
    "ap.run(m=m, nmax=nmax, estBurnin=True, mcmcKwargs=mcmcKwargs, \n",
    "       cache=True, samplerKwargs=samplerKwargs, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's see what the joint and marginal posterior distributions look like for a few iterations.**\n",
    "\n",
    "---\n",
    "\n",
    "Below, I plot the joint and marginal posterior probability distributions.  The red points indicate where in parameter space the BAPE algorithm evaluated the forward model to improve its predictive ability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0th iteration...\n",
    "reader = emcee.backends.HDFBackend(ap.backends[0])\n",
    "samples = reader.get_chain(discard=ap.iburns[0], flat=True, thin=ap.ithins[0])\n",
    "\n",
    "fig = corner.corner(samples, quantiles=[0.16, 0.5, 0.84], show_titles=True, \n",
    "                    scale_hist=True, plot_contours=True);\n",
    "\n",
    "# Plot where forward model was evaluated\n",
    "fig.axes[2].scatter(ap.theta[:(m0+m),0], ap.theta[:(m0+m),1], s=10, color=\"red\", zorder=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final iteration!\n",
    "reader = emcee.backends.HDFBackend(ap.backends[-1])\n",
    "samples = reader.get_chain(discard=ap.iburns[-1], flat=True, thin=ap.ithins[-1])\n",
    "\n",
    "fig = corner.corner(samples, quantiles=[0.16, 0.5, 0.84], show_titles=True, \n",
    "                    scale_hist=True, plot_contours=True);\n",
    "\n",
    "# Plot where forward model was evaluated\n",
    "fig.axes[2].scatter(ap.theta[:,0], ap.theta[:,1], s=10, color=\"red\", zorder=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The posteriors look great and BAPE only evaluated the forward model in high likelihood regions of parameter space!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
